# -*- coding: utf-8 -*-
"""ML Script for selecting 379 important miRNAs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BhuuGSszgr_iZ0-yo3zgi0BpZhFdbVh3
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from os import pardir, path
import warnings
warnings.filterwarnings("ignore")
# %matplotlib inline
import matplotlib.pyplot as plt
from scipy import stats
import glob
import seaborn as sns


# %config InlineBackend.figure_format = 'retina'
sns.set_style("white")

base = '/content/drive/MyDrive/Rooge_Project/'
base

df = pd.read_csv(base+'merge set 2and4.csv').T
df = df.rename(columns=df.iloc[0]).iloc[1:,:]

label_df = pd.read_csv(base+'Factors set2and4 (3 groups).csv').iloc[:,:3]
label_df['Type'] = label_df['Type'].str.replace(' ','')
# label_df['Class'] = label_df['Type']+'_'+label_df['Sample type']
label_df['Class'] = label_df['Type']
label_df = label_df.set_index('Sample Name')

rawData = pd.concat([df,label_df['Class']], axis=1).fillna(0)
rawData

# rawData.loc[:,pd.read_csv('Importance features.csv')['miRNA']].T.to_csv('Machine learning miRNA.csv')

# data = rawData[(rawData['Class'] != 'AIS_Discharge') & (rawData['Class'] != 'HSIL_Discharge')]

data = rawData
stat = pd.DataFrame(data.groupby(['Class']).agg(['count']).iloc[:,-1])
stat.columns = ['Count']
stat['Percentage'] = round(stat['Count']/stat['Count'].sum()*100,3)
stat

from sklearn import preprocessing
from sklearn.preprocessing import RobustScaler
from sklearn.preprocessing import label_binarize
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn import metrics

from sklearn.model_selection import StratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict

# Normalized data
RS = preprocessing.RobustScaler()
scaled_df = pd.DataFrame(RS.fit_transform(data.iloc[:,:-1]) , columns= data.iloc[:,:-1].columns, index=data.index)
scaled_df['Target'] = data['Class']

# Train and Test spliting with 0.67 and 0.33 respectively
X_train, X_test, y_train, y_test = train_test_split(scaled_df.iloc[:,:-1], scaled_df['Target'], 
                                                    test_size=0.33) # , random_state=7

Model_Name = 'RandomForestClassifier'
model=RandomForestClassifier() # step 1: choose model/estimator for classification
# model=LogisticRegression()
model.fit(X_train, y_train) # step 2: fit
y_pred=model.predict(X_test) # step 3: predict
print('Accuracy score:', model.score(X_test, y_test).round(3)) # step 4: accuracy score for classification r2 for regression
# classes=['AIS_Discharge', 'AIS_tissue','HSIL_Discharge','HSIL_tissue','Normal_tissue']
classes=list(set(data['Class']))
print(metrics.classification_report(y_test, y_pred, target_names=classes))
y_pred_prob = model.predict_proba(X_test)[::,1]

# show classification result
result = pd.concat([y_test.reset_index(),pd.DataFrame([y_pred,y_pred_prob]).T],axis=1)
result.columns = ['Patient','Class','Predicted','Predicted_Prob']
result

"""![image.png](attachment:image.png)"""

# Train Test spliting and 10 fold Cross validation

print('Performance of classification model before feature selection')
scaled_df = pd.DataFrame(RS.fit_transform(data.iloc[:,:-1]) , columns= data.iloc[:,:-1].columns, index=data.index)
scaled_df['Target'] = data['Class']

cv = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)
X=scaled_df.iloc[:,:-1]
print('Number of all features ', X.shape)
y=scaled_df['Target']
scores = cross_val_score(model, X,y, scoring='accuracy',cv=cv,n_jobs=-1)
print('Accuracy: %.3f (%.3f)'% (np.mean(scores),np.std(scores)))


# Feature selection by using Random Forest
importance = model.feature_importances_
importance_score = pd.DataFrame([X.columns, importance]).T
importance_score.columns = ['miRNA','Score']
importance_score = importance_score.sort_values(by='Score', ascending=False)
miRNA1 = importance_score[importance_score['Score'] > 0]['miRNA']

print("\n",'*'*30)
print('Performance of classification model after feature selection')
cv = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)
X=scaled_df.loc[:,miRNA1]
print('Number of Selected features ', X.shape)
y=scaled_df['Target']
scores = cross_val_score(model, X,y, scoring='accuracy',cv=cv,n_jobs=-1)
print('Accuracy: %.3f (%.3f)'% (np.mean(scores),np.std(scores)))

X_train, X_test, y_train, y_test = train_test_split(scaled_df.iloc[:,:-1], scaled_df['Target'], 
                                                    test_size=0.33)
y_pred=model.predict(X_test) # step 3: predict
print('Accuracy score:', model.score(X_test, y_test).round(3)) # step 4: accuracy score for classification r2 for regression
# classes=['AIS_Discharge', 'AIS_tissue','HSIL_Discharge','HSIL_tissue','Normal_tissue']
classes=list(set(data['Class']))
print(metrics.classification_report(y_test, y_pred, target_names=classes))
# print('-' * 100)

y_pred_prob = model.predict_proba(X_test)[::,1]

result = pd.concat([y_test.reset_index(),pd.DataFrame([y_pred,y_pred_prob]).T],axis=1)
result.columns = ['Patient','Class','Predicted','Predicted_Prob']
result

# 3 times Upsampling on AIS and Normal group
from sklearn.utils import resample
up_df = pd.DataFrame()
for c in ['AIS', 'Normal']:
    sampling = data[data['Class'] == c]
    up_sampling = resample(sampling, replace=True, n_samples=sampling.shape[0]*3, random_state=123)
    up_df = up_df.append(up_sampling)

# hsil = data[(data['Class'] == 'HSIL_Discharge') | (data['Class'] == 'HSIL_tissue')]
hsil  = data[data['Class']== 'HSIL']

new_data = hsil.append(up_df)

# Normalization
scaled_df = pd.DataFrame(RS.fit_transform(new_data.iloc[:,:-1]) , columns= new_data.iloc[:,:-1].columns, 
                         index=new_data.index)
scaled_df['Target'] = new_data['Class']
# 10 Fold Cross Validation
cv = StratifiedKFold(n_splits=10, random_state=12, shuffle=True)
X=scaled_df.iloc[:,:-1]
print('Number of all features ', X.shape)
y=scaled_df['Target']
scores = cross_val_score(model, X,y, scoring='accuracy',cv=cv,n_jobs=-1)
print('Accuracy: %.3f (%.3f)'% (np.mean(scores),np.std(scores)))

print("\n",'*'*30)
print('Performance of classification model after feature selection')
importance = model.feature_importances_
importance_score = pd.DataFrame([X.columns, importance]).T
importance_score.columns = ['miRNA','Score']
importance_score = importance_score.sort_values(by='Score', ascending=False)


miRNA2 = importance_score[importance_score['Score'] > 0]['miRNA']

cv = StratifiedKFold(n_splits=10, random_state=12, shuffle=True)
X=scaled_df.loc[:,miRNA2]
print('Number of Selected features ', X.shape)
y=scaled_df['Target']
scores = cross_val_score(model, X,y, scoring='accuracy',cv=cv,n_jobs=-1)
print('Accuracy: %.3f (%.3f)'% (np.mean(scores),np.std(scores)))

stat = pd.DataFrame(new_data.groupby(['Class']).agg(['count']).iloc[:,-1])
stat.columns = ['Count']
stat['Percentage'] = round(stat['Count']/stat['Count'].sum()*100,3)
stat